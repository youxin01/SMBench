from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from langchain_mcp_adapters.tools import load_mcp_tools
from langgraph.prebuilt import create_react_agent
import asyncio
import sys
from langchain_openai import ChatOpenAI
import os
from langchain_core.messages import SystemMessage, HumanMessage,AIMessage

def extract_to_txt(response, output_file1: str, output_file2: str) -> None:
    """
    æå–responseä¸­çš„æœ‰æ•ˆä¿¡æ¯å¹¶åˆ†åˆ«ä¿å­˜åˆ°ä¸¤ä¸ªæ–‡ä»¶
    
    Args:
        response: åŒ…å«æ¶ˆæ¯çš„å­—å…¸ï¼Œåº”æœ‰"messages"é”®
        output_file1: ä¿å­˜åŸå§‹å“åº”æ•°æ®çš„æ–‡ä»¶å
        output_file2: ä¿å­˜æå–åçš„ç»“æ„åŒ–ä¿¡æ¯çš„æ–‡ä»¶å
    """
    # ä¿å­˜åŸå§‹å“åº”åˆ°ç¬¬ä¸€ä¸ªæ–‡ä»¶
    try:
        with open(output_file1, 'w', encoding='utf-8') as f:
            f.write(str(response))
        print(f"Successfully saved raw response to {output_file1}")
    except Exception as e:
        print(f"Error writing raw response to file: {e}")
        return

    # æå–ç»“æ„åŒ–ä¿¡æ¯
    content_lines = []
    
    for msg in response["messages"]:
        # å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼ˆPromptï¼‰
        if isinstance(msg, HumanMessage):
            content_lines.append(f"[USER PROMPT]\n{msg.content}\n\n")
        
        # å¤„ç†AIçš„å·¥å…·è°ƒç”¨
        elif isinstance(msg, AIMessage) and msg.additional_kwargs.get("tool_calls"):
            for call in msg.additional_kwargs["tool_calls"]:
                tool_call = call["function"]
                content_lines.append(
                    f"[FUNCTION CALL]\n"
                    f"Name: {tool_call.get('name', 'N/A')}\n"
                    f"Arguments: {tool_call.get('arguments', 'N/A')}\n\n"
                )
        # å¤„ç†AIçš„æœ€ç»ˆå›ç­”
        elif isinstance(msg, AIMessage):
            content_lines.append(f"[AI RESPONSE]\n{msg.content}\n\n")
    
    if not content_lines:
        print("No valid messages found in the response.")
        return
    
    # ä¿å­˜æå–åçš„ä¿¡æ¯åˆ°ç¬¬äºŒä¸ªæ–‡ä»¶
    try:
        with open(output_file2, "w", encoding="utf-8") as f:
            f.writelines(content_lines)
        print(f"Successfully saved extracted information to {output_file2}")
    except Exception as e:
        print(f"Error writing extracted information to file: {e}")

# # 1. é¦–å…ˆè®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥ï¼ˆå¿…é¡»åœ¨æ‰€æœ‰å¼‚æ­¥æ“ä½œä¹‹å‰ï¼‰
# if sys.platform == "win32":
#     asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

# 2. åˆå§‹åŒ–æ¨¡å‹
model = ChatOpenAI(
    model="deepseek-chat",
    temperature=0,
    max_tokens=None,
    timeout=None,
    api_key="",
    base_url="https://api.deepseek.com/v1",
)

current_dir = os.path.dirname(os.path.abspath(__file__))
# æ‹¼æ¥ math_server.py çš„ç»å¯¹è·¯å¾„
math_server_path = os.path.join(current_dir, "mcp_ver.py")

# 4. é…ç½®æœåŠ¡å™¨å‚æ•°ï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
server_params = StdioServerParameters(
    command="python",
    args=[math_server_path],  # ä½¿ç”¨ç»å¯¹è·¯å¾„
)

system="""
ä½ æ˜¯ä¸€ä¸ªæ•°å­¦å»ºæ¨¡ä¸“å®¶ï¼Œæ“…é•¿è°ƒç”¨toolsæ¥è§£å†³å„ç§å»ºæ¨¡é—®é¢˜ã€‚
"""

async def main():
    try:
        print("æ­£åœ¨è¿æ¥æœåŠ¡å™¨...")
        async with stdio_client(server_params) as (read, write):
            print("æœåŠ¡å™¨è¿æ¥æˆåŠŸï¼Œåˆ›å»ºä¼šè¯...")
            print(math_server_path)
            async with ClientSession(read, write) as session:
                await session.initialize()
                print("æ­£åœ¨åŠ è½½å·¥å…·...")
                tools = await load_mcp_tools(session)
                print(f"å·²åŠ è½½å·¥å…·: {[t.name for t in tools]}")

                agent = create_react_agent(model, tools)
                print("ä»£ç†å·²åˆ›å»ºï¼Œå¼€å§‹å¯¹è¯...")

                # åˆå§‹å¯¹è¯å†å²
                messages = [SystemMessage(content=system)]

                while True:
                    user_input = input("\nğŸ§‘ ä½ è¯´ï¼š").strip()
                    if user_input.lower() in {"exit", "quit"}:
                        print("âœ… å¯¹è¯ç»“æŸ")
                        break

                    # åŠ å…¥ç”¨æˆ·æ¶ˆæ¯
                    messages.append(HumanMessage(content=user_input))

                    # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                    raw_messages = []
                    for m in messages:
                        if isinstance(m, SystemMessage):
                            raw_messages.append({"role": "system", "content": m.content})
                        elif isinstance(m, HumanMessage):
                            raw_messages.append({"role": "user", "content": m.content})
                        elif isinstance(m, AIMessage):
                            raw_messages.append({"role": "assistant", "content": m.content})

                    # è°ƒç”¨ agent
                    response = await agent.ainvoke({"messages": raw_messages})

                    # æå– AI å›å¤
                    reply = response['messages'][-1].content
                    print("\nğŸ¤– AI å›ç­”ï¼š")
                    print(reply)

                    ai_msg = response['messages'][-1]
                    messages.append(ai_msg)

                    # # é€‰åšï¼šä¿å­˜æ¯è½®ç»“æœ
                # print(response)
                extract_to_txt(response=response, output_file1="./original.txt", output_file2="./ex_result.txt")

    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {str(e)}")
        raise


# 5. ç¡®ä¿ä¸»ç¨‹åºå…¥å£æ­£ç¡®
if __name__ == "__main__":
    print("å¯åŠ¨ä¸»ç¨‹åº...")
    asyncio.run(main())